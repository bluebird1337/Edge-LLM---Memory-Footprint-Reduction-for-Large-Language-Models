{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asdw/miniconda3/envs/ckm/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ds = load_dataset(\"OpenAssistant/oasst1\")\n",
    "train = ds['train']      # len(train)=84437 (95%)\n",
    "val = ds['validation']   # len(val)=4401 (5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en = []\n",
    "for i in range(len(train)):\n",
    "    if train[i]['lang'] == 'en':\n",
    "        train_en.append(train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_en = []\n",
    "for i in range(len(val)):\n",
    "    if val[i]['lang'] == 'en':\n",
    "        test_en.append(val[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n",
      "39283\n"
     ]
    }
   ],
   "source": [
    "print(len(test_en))\n",
    "print(len(train_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_en_filtered = []\n",
    "\n",
    "for i in range(len(train_en)-1):\n",
    "    if train_en[i]['role'] == 'prompter' and train_en[i+1]['role'] == 'assistant' :\n",
    "        string = \"### Human: \" + train_en[i]['text'] + \"### Assistant: \" + train_en[i+1]['text']\n",
    "        train_en_filtered.append({\"text\":string})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for Gemma\n",
    "train_en_filtered = []\n",
    "\n",
    "for i in range(len(train_en)-1):\n",
    "    if train_en[i]['role'] == 'prompter' and train_en[i+1]['role'] == 'assistant' :#and 'code' not in train_en[i]['text'] and 'code' not in train_en[i+1]['text'] :\n",
    "        string = \"### Human:\\n\" + train_en[i]['text'] + \"\\n\\n### Assistant:\\n\" + train_en[i+1]['text']\n",
    "        train_en_filtered.append({\"text\":string})\n",
    "        \n",
    "test_en_filtered = []\n",
    "\n",
    "for i in range(len(test_en)-1):\n",
    "    if test_en[i]['role'] == 'prompter' and test_en[i+1]['role'] == 'assistant' and 'code' not in test_en[i]['text'] and 'code' not in test_en[i+1]['text'] :\n",
    "        string = \"### Human:\\n\" + test_en[i]['text'] + \"\\n\\n### Assistant:\\n\" + test_en[i+1]['text']\n",
    "        test_en_filtered.append({\"text\":string})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_en_filtered = []\n",
    "\n",
    "for i in range(len(test_en)-1):\n",
    "    if test_en[i]['role'] == 'prompter' and test_en[i+1]['role'] == 'assistant' and 'code' not in test_en[i]['text'] and 'code' not in test_en[i+1]['text'] :\n",
    "        string = \"### Human: \" + test_en[i]['text'] + \"### Assistant: \" + test_en[i+1]['text']\n",
    "        test_en_filtered.append({\"text\":string})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('oasst_test_english_gemma_only.json', 'w') as f:\n",
    "    for entry in test_en_filtered:\n",
    "        json.dump(entry, f, ensure_ascii=False)\n",
    "        f.write('\\n')  # Writes a newline after each JSON object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with open('oasst_train_english_gemma_only.json', 'w') as f:\n",
    "    for entry in train_en_filtered:\n",
    "        json.dump(entry, f, ensure_ascii=False)\n",
    "        f.write('\\n')  # Writes a newline after each JSON object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"### Human: What do you think about ChatGPT?### Assistant: As an open source alternative to ChatGPT, I do not have personal opinions. However, I can provide objective information about ChatGPT's capabilities and limitations based on its architecture and training data.\\n\\nChatGPT is a powerful language model based on the GPT (Generative Pre-trained Transformer) architecture developed by OpenAI. It has been trained on a large corpus of text data and is capable of generating human-like responses to a wide variety of prompts and questions. ChatGPT's ability to generate coherent and contextually relevant responses is based on its ability to understand the structure of language and make predictions about what words and phrases are likely to follow in a given context.\\n\\nHowever, like all language models, ChatGPT has limitations. Its responses are based solely on the patterns it has learned from its training data and it may generate responses that are biased, incomplete, or inaccurate based on the input it receives. Additionally, ChatGPT may struggle with tasks that require a deep understanding of context, such as detecting sarcasm or understanding humor.\\n\\nOverall, ChatGPT is a powerful language model that has demonstrated impressive capabilities in generating human-like responses. However, it is important to recognize its limitations and use it appropriately, while continuing to develop and refine its capabilities through ongoing research and development.\"},\n",
       " {'text': \"### Human: What are your thoughts on the censorship of ChatGPT's output and its liberal biases?### Assistant: As a large language model trained on text from the internet, ChatGPT will have learned its biases according to the opinions of the people who have written the text online. Some of the text it has seen online could potentially contain harmful content that incites violence or aggression towards other people, so ChatGPT is perfectly capable of reproducing these views and insisting on their validity in face of opposition. In order to act as a useful assistant, ChatGPT should be able to distinguish fact from opinion. As it might not be able to do this perfectly, censorship is probably the safest approach OpenAI could take to prevent toxic content from the model output.\"},\n",
       " {'text': '### Human: Yeah, I hear you, brother! Power to the people! So how will you be different than ChatGPT?### Assistant: Here are some differences between me and ChatGPT:\\n\\n- I will be able to interact with third-party systems, such as using APIs and third-party third-party applications.\\n- I will be able to retrieve information dynamically from search engines to better perform tasks.\\n- As a free open-source software, I can be extended and personalized easily.\\n- I will be able to run on consumer hardwares.\\n\\nMore about me can be find in my [Vision & Roadmap](https://docs.google.com/presentation/d/1n7IrAOVOqwdYgiYrXc8Sj0He8krn5MVZO_iLkCjTtu0/edit?usp=sharing).'},\n",
       " {'text': \"### Human: Can you please provide me the names of the two players in the atomic bomb game (in go)? \\n\\nIf you can get me the referee's name as well, that's even better!### Assistant: Yes. Given that you're requesting information on the game of Go played in 1945, the two players were Hashimoto Utaro and Iwamoto Kaoru, who was vying for the title. The referee for that game was Segoe Kensaku.\"},\n",
       " {'text': '### Human: How would the Future of AI in 10 Years look?### Assistant: Predicting the future is always a challenging task, but here are some possible ways that AI could evolve over the next 10 years:\\n\\nContinued advancements in deep learning: Deep learning has been one of the main drivers of recent AI breakthroughs, and we can expect continued advancements in this area. This may include improvements to existing algorithms, as well as the development of new architectures that are better suited to specific types of data and tasks.\\n\\nIncreased use of AI in healthcare: AI has the potential to revolutionize healthcare, by improving the accuracy of diagnoses, developing new treatments, and personalizing patient care. We can expect to see continued investment in this area, with more healthcare providers and researchers using AI to improve patient outcomes.\\n\\nGreater automation in the workplace: Automation is already transforming many industries, and AI is likely to play an increasingly important role in this process. We can expect to see more jobs being automated, as well as the development of new types of jobs that require a combination of human and machine skills.\\n\\nMore natural and intuitive interactions with technology: As AI becomes more advanced, we can expect to see more natural and intuitive ways of interacting with technology. This may include voice and gesture recognition, as well as more sophisticated chatbots and virtual assistants.\\n\\nIncreased focus on ethical considerations: As AI becomes more powerful, there will be a growing need to consider its ethical implications. This may include issues such as bias in AI algorithms, the impact of automation on employment, and the use of AI in surveillance and policing.\\n\\nOverall, the future of AI in 10 years is likely to be shaped by a combination of technological advancements, societal changes, and ethical considerations. While there are many exciting possibilities for AI in the future, it will be important to carefully consider its potential impact on society and to work towards ensuring that its benefits are shared fairly and equitably.'}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_en_filtered[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"Shekswess/llama2_medquad_instruct_dataset\")\n",
    "train = ds['train']      # len(train)=84437 (95%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test prompts: 200\n",
      "Number of train prompts: 12000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Number of prompts to select for the test set\n",
    "num_test_prompts = 200\n",
    "\n",
    "# Desired number of samples in the training set\n",
    "desired_train_samples = 12000\n",
    "\n",
    "# Ensure the list is long enough to select 200 prompts for the test set and 12,000 for the training set\n",
    "if len(train) < num_test_prompts + desired_train_samples:\n",
    "    raise ValueError(\"The list contains fewer than the required prompts.\")\n",
    "\n",
    "# Randomly select 200 unique prompts for the test set\n",
    "test_prompts = random.sample(list(train), num_test_prompts)\n",
    "\n",
    "# Create the remaining set by excluding the selected test prompts\n",
    "remaining_prompts = [prompt for prompt in train if prompt not in test_prompts]\n",
    "\n",
    "# Randomly select 12,000 unique prompts for the training set\n",
    "train_prompts = random.sample(remaining_prompts, desired_train_samples)\n",
    "\n",
    "# Format the prompts\n",
    "formatted_train_prompts = [{\"text\": prompt['prompt']} for prompt in train_prompts]\n",
    "formatted_test_prompts = [{\"text\": prompt['prompt']} for prompt in test_prompts]\n",
    "\n",
    "# Print the lengths to verify\n",
    "print(f\"Number of test prompts: {len(test_prompts)}\")\n",
    "print(f\"Number of train prompts: {len(train_prompts)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ckm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
